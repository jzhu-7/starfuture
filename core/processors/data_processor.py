"""
æ•°æ®å¤„ç†æ¨¡å—
è´Ÿè´£æ•°æ®æ›´æ–°ã€è®¡ç®—å’Œæ•´åˆé€»è¾‘
"""
import os
import json
import requests
import logging
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from bs4 import BeautifulSoup

from config import DATA_URL, HEADERS, TOTAL_FILE, AREAS_FILE
from utils import fetch_html
from scrapers.status_scraper import get_status_changes
from models import SalesStats, StatusChange

logger = logging.getLogger(__name__)

def read_json_as_dict(json_file: str) -> Dict[str, Dict]:
    """ä»¥æ—¥æœŸä¸ºkeyè¯»å–JSON"""
    if not os.path.exists(json_file):
        return {}

    with open(json_file, "r", encoding="utf-8") as f:
        data = json.load(f)
        return {item["æ—¥æœŸ"]: item for item in data}

def write_json(data_by_date: Dict[str, Dict], json_file: str):
    """å†™å…¥JSONæ–‡ä»¶"""
    data_list = [data_by_date[d] for d in sorted(data_by_date.keys())]
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(data_list, f, ensure_ascii=False, indent=4)

def find_base_record(data_by_date: Dict[str, Dict], today: str) -> Optional[Dict]:
    """æ‰¾åˆ°ç”¨äºå¯¹æ¯”çš„ä¸Šä¸€æ¡è®°å½•"""
    dates = sorted(data_by_date.keys())
    if not dates:
        return None

    if dates[-1] != today:
        return data_by_date[dates[-1]]

    if len(dates) >= 2:
        return data_by_date[dates[-2]]

    return None

def parse_presale_contract_stats(html: str) -> Optional[SalesStats]:
    """è§£ææœŸæˆ¿ç­¾çº¦ç»Ÿè®¡æ•°æ®"""
    soup = BeautifulSoup(html, "html.parser")

    title_td = soup.find(
        lambda tag: tag.name == "td" and "æœŸæˆ¿ç­¾çº¦ç»Ÿè®¡" in tag.get_text()
    )
    if not title_td:
        return None

    outer_table = title_td.find_parent("table")
    data_table = outer_table.find_all("table")[0]

    rows = data_table.find_all("tr")
    headers = [td.get_text(strip=True) for td in rows[0].find_all("td")]
    values = [td.get_text(strip=True) for td in rows[1].find_all("td")]
    data = dict(zip(headers, values))

    return SalesStats(
        signed_units=int(data.get("å·²ç­¾çº¦å¥—æ•°", 0)),
        signed_area=float(data.get("å·²ç­¾çº¦é¢ç§¯(M2)", "0")),
        avg_price=float(data.get("æˆäº¤å‡ä»·(ï¿¥/M2)", "0")),
    )

def build_house_area_map() -> Dict[str, Dict[str, float]]:
    """æ„å»ºæˆ¿æºé¢ç§¯æ˜ å°„"""
    if not os.path.exists(AREAS_FILE):
        raise FileNotFoundError(f"é¢ç§¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {AREAS_FILE}")

    with open(AREAS_FILE, 'r', encoding='utf-8') as f:
        areas_data = json.load(f)

    house_area_map = {}
    for building, bdata in areas_data.items():
        house_area_map[building] = {h["house_no"]: h["area"] for h in bdata["house_data"]}

    return house_area_map

def calculate_incremental_data(stats: SalesStats, base_record: Optional[Dict]) -> Tuple[float, str, str]:
    """è®¡ç®—å¢é‡æ•°æ®"""
    cur_area = stats.signed_area
    cur_price = stats.avg_price

    # åŸºå‡†æ•°æ®
    prev_area = float(base_record["å·²ç­¾çº¦é¢ç§¯(M2)"]) if base_record else 0.0
    prev_price = float(base_record["æˆäº¤å‡ä»·(ï¿¥/M2)"]) if base_record else 0.0
    prev_total = prev_area * prev_price

    # å¢é‡è®¡ç®—
    delta_area = round(cur_area - prev_area, 2)

    if delta_area > 0:
        cur_total = cur_area * cur_price
        delta_total = round(cur_total - prev_total, 2)
        delta_unit = round(delta_total / delta_area, 2)
    else:
        delta_total = ""
        delta_unit = ""

    return delta_area, delta_total, delta_unit

def process_status_changes(changes: List[StatusChange], house_area_map: Dict[str, Dict[str, float]]) -> List[Dict]:
    """å¤„ç†çŠ¶æ€å˜åŒ–ï¼Œæ·»åŠ é¢ç§¯ä¿¡æ¯"""
    processed_changes = []

    for change in changes:
        if change.prev_status == "å¯å”®":
            building_name = change.building_name
            house_no = change.house_no

            area = house_area_map.get(building_name, {}).get(house_no, 0.0)

            processed_changes.append({
                "building_name": building_name,
                "house_no": house_no,
                "area": area
            })

    return processed_changes

def update_sales_data() -> bool:
    """ä¸»æ•°æ®æ›´æ–°æµç¨‹"""
    try:
        # æ„å»ºæˆ¿æºé¢ç§¯æ˜ å°„
        house_area_map = build_house_area_map()

        today = datetime.now().strftime("%Y-%m-%d")

        logger.info("ğŸŒ è¯·æ±‚é¡µé¢...")
        resp = requests.get(DATA_URL, headers=HEADERS, timeout=15)
        resp.raise_for_status()
        resp.encoding = "utf-8"

        stats = parse_presale_contract_stats(resp.text)
        if not stats:
            logger.error("âŒ æœªè·å–æœŸæˆ¿ç­¾çº¦ç»Ÿè®¡")
            return False

        data_by_date = read_json_as_dict(TOTAL_FILE)
        base_record = find_base_record(data_by_date, today)

        # è®¡ç®—å¢é‡æ•°æ®
        delta_area, delta_total, delta_unit = calculate_incremental_data(stats, base_record)

        # å†™å…¥å½“å¤©æ•°æ®
        data_by_date[today] = {
            "æ—¥æœŸ": today,
            "å·²ç­¾çº¦å¥—æ•°": stats.signed_units,
            "å·²ç­¾çº¦é¢ç§¯(M2)": round(stats.signed_area, 2),
            "æˆäº¤å‡ä»·(ï¿¥/M2)": round(stats.avg_price, 2),
            "æˆäº¤æˆ·å·": [],  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨
            "é¢ç§¯(M2)": delta_area if delta_area > 0 else "",
            "æ€»ä»·(ï¿¥)": delta_total,
            "å‡ä»·(ï¿¥/M2)": delta_unit,
        }

        # å¦‚æœæœ‰æ–°æ•°æ®ï¼Œå¤„ç†çŠ¶æ€å˜åŒ–
        if delta_area > 0:
            changes = get_status_changes()
            if changes:
                processed_changes = process_status_changes(changes, house_area_map)
                data_by_date[today]["æˆäº¤æˆ·å·"] = processed_changes

        # é‡å†™JSONæ–‡ä»¶
        write_json(data_by_date, TOTAL_FILE)

        logger.info(f"âœ… {today} æ•°æ®å·²å†™å…¥ï¼ˆåŒæ—¥è‡ªåŠ¨è¦†ç›–ï¼‰")
        return True

    except Exception as e:
        logger.error(f"âŒ æ•°æ®æ›´æ–°å¤±è´¥: {e}")
        return False